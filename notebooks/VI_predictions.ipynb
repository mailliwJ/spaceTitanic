{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils.cleanTransform import cleanTransform as ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 1. Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "predict = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "target = 'Transported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    df = ct.transform_passengerId(df)\n",
    "    df = ct.transform_Cabin(df)\n",
    "    df = ct.impute_homePlanet(df)\n",
    "    df = ct.proportional_imputer(df, impute_cols=['Destination', 'Deck', 'Side', 'CabinPosition', 'VIP', 'CryoSleep'])\n",
    "    df = ct.knn_imputer(df, columns=['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'])\n",
    "    df = ct.create_totalSpent(df)\n",
    "    df = ct.oneHot(df, oh_cols=['HomePlanet','Destination','Deck','Side','CabinPosition','GroupSize'])\n",
    "    df = ct.numPipe(df, num_cols=['Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','TotalSpent'])\n",
    "    df = ct.convert_to_int(df)\n",
    "    df = ct.drop_cols(df, drop_cols=['PassengerNumber','GroupId','Cabin','CabinNumber','Name'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process using functions in cleanTransform module\n",
    "train = ct.process_dataframe(train)\n",
    "predict = ct.process_dataframe(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and predicting\n",
    "X_train, y_train = train.drop(['PassengerId',target], axis=1), train[target]\n",
    "X_pred = predict.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate algorithms\n",
    "rf = RandomForestClassifier(max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, random_state=13)\n",
    "lgbm = LGBMClassifier(learning_rate=0.01, max_depth=-1, n_estimators=300, num_leaves=31, random_state=13, verbose=-1)\n",
    "xgbm = XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8, random_state=13, verbosity=0)\n",
    "\n",
    "# Store algorithms in a dictionary\n",
    "algs = {'rf':rf, 'lgbm':lgbm, 'xgbm':xgbm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate an empty dictionary to store to fitted models\n",
    "models = {}\n",
    "# Intatiate another empty dictionary to save predictions in\n",
    "predictions = {}\n",
    "\n",
    "# Iterate over algorithms and fit to training data\n",
    "for name, alg in algs.items():\n",
    "    models[name] = alg.fit(X_train, y_train)    # Store fitted models in models dictionary\n",
    "    predictions[name] = models[name].predict(X_pred).astype(bool)    # Store predictions in predictions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over predictions and convert each to a dataframe with 'PassengerId' from test and prediction\n",
    "for model, preds in predictions.items():\n",
    "    predictions[model] = pd.DataFrame({\n",
    "            'PassengerId': predict['PassengerId'],\n",
    "            'Transported': preds\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each dataframe for submision to Kaggle\n",
    "for model, df in predictions.items():\n",
    "    df.to_csv(f'../submissions/predictions_{model}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
